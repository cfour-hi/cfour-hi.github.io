---
title: 机器学习基础-监督学习-线性回归之多项式回归
categories: [机器学习]
tags: [人工智能, 机器学习, 监督学习]
math: true
---

多项式回归是一种线性回归的扩展，通过引入多项式特征来拟合非线性关系。下面详细讲解多项式回归的原理，并提供一个 Python 代码示例。

多项式回归的模型形式为：

$$
y = \beta_0 + \beta_1x + \beta_2x^2 + ... + \beta_nx^n + \epsilon
$$

其中，y 是目标变量，x 是输入特征，β₀, β₁, β₂, ..., βₙ 是回归系数，ε 是误差项。

多项式回归的步骤如下：

数据准备：准备包含特征变量和目标变量的训练数据集。

特征变换：将输入特征 x 转换为多项式特征。可以使用 NumPy 库中的 polyfit 函数或者 Scikit-learn 库中的 PolynomialFeatures 类来实现。

模型训练：使用线性回归算法来拟合多项式特征。可以使用 Scikit-learn 库中的 LinearRegression 类来实现。

模型评估：使用评估指标（如均方误差）来评估模型的性能。

下面是一个使用 Scikit-learn 库进行多项式回归的 Python 代码示例：

```python
import numpy as np
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

# 准备示例数据
X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)  # 输入特征
y = np.array([2, 8, 18, 32, 50])  # 目标变量

# 转换为多项式特征
poly = PolynomialFeatures(degree=2)  # 设置多项式的阶数
X_poly = poly.fit_transform(X)

# 拟合多项式回归模型
model = LinearRegression()
model.fit(X_poly, y)

# 预测
X_test = np.array([6]).reshape(-1, 1)  # 测试数据
X_test_poly = poly.transform(X_test)
y_pred = model.predict(X_test_poly)
print("预测结果:", y_pred)

# 绘制拟合曲线
X_grid = np.arange(min(X), max(X), 0.1).reshape(-1, 1)
X_grid_poly = poly.transform(X_grid)
y_pred_grid = model.predict(X_grid_poly)

plt.scatter(X, y, color='red', label='实际数据')
plt.plot(X_grid, y_pred_grid, color='blue', label='拟合曲线')
plt.title('多项式回归')
plt.xlabel('X')
plt.ylabel('y')
plt.legend()
plt.show()
```

在上述代码中，我们首先使用 PolynomialFeatures 类将输入特征 X 转换为二次多项式特征 X_poly。然后使用 LinearRegression 类来拟合多项式特征和目标变量 y。最后，我们使用拟合的模型对新的输入特征 X_test 进行预测，并绘制了实际数据和拟合曲线的散点图和线性图。

这个示例代码中，我们使用二次多项式特征（degree=2），因此模型会拟合一个二次曲线来适应数据。你可以根据需要调整 degree 的值来尝试更高阶的多项式回归。

需要注意的是，多项式回归也有可能出现过拟合的情况，当多项式的阶数过高时，模型可能过于复杂，对训练数据拟合得很好，但在新的数据上的表现可能较差。因此，在应用多项式回归时，需要权衡模型的复杂性和数据的拟合程度。
