---
title: 机器学习基础-监督学习-无监督标签之降维
categories: [机器学习]
tags: [人工智能, 机器学习, 监督学习]
math: true
---

降维是一种常见的无监督学习任务，其目标是将高维数据映射到低维空间，以减少数据的特征维度，同时保留数据的关键结构和信息。通过降维，可以简化数据表示、减少存储空间、降低计算复杂度，并帮助可视化和数据理解。

降维方法的选择取决于数据的性质、任务需求和算法的适用性。以下是一些常见的降维方法：

1. 主成分分析(Principal Component Analysis, PCA)：

PCA 是一种常用的线性降维技术，它通过找到数据中的主要方差方向来实现降维。PCA 将原始数据映射到新的低维空间，其中新的特征被称为主成分。每个主成分都是原始特征的线性组合，其排序是根据对应的方差来确定。

```python
from sklearn.datasets import load_iris
from sklearn.decomposition import PCA

# 加载鸢尾花数据集
iris = load_iris()
X = iris.data

# 使用PCA进行降维
pca = PCA(n_components=2)
X_reduced = pca.fit_transform(X)

# 打印降维后的数据
print("降维后的数据：")
print(X_reduced)
```

2. 线性判别分析(Linear Discriminant Analysis, LDA)：

LDA 也是一种常用的线性降维方法，它与 PCA 不同的是，LDA 考虑了样本的类别信息。LDA 试图在降维的过程中保留类别之间的差异，以找到更具有判别性的特征。因此，LDA 在分类问题中特别有用。

```python
from sklearn.datasets import load_iris
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

# 加载鸢尾花数据集
iris = load_iris()
X = iris.data
y = iris.target

# 使用LDA进行降维
lda = LinearDiscriminantAnalysis(n_components=2)
X_reduced = lda.fit_transform(X, y)

# 打印降维后的数据
print("降维后的数据：")
print(X_reduced)
```

3. t 分布邻域嵌入(t-Distributed Stochastic Neighbor Embedding, t-SNE)：

t-SNE 是一种非线性降维方法，它在可视化和数据挖掘中广泛使用。t-SNE 通过保留数据样本之间的局部关系，将高维数据映射到二维或三维空间。它能够更好地保留样本之间的相似性，尤其适用于数据聚类和类别可视化。

```python
from sklearn.datasets import load_iris
from sklearn.manifold import TSNE

# 加载鸢尾花数据集
iris = load_iris()
X = iris.data

# 使用t-SNE进行降维
tsne = TSNE(n_components=2)
X_reduced = tsne.fit_transform(X)

# 打印降维后的数据
print("降维后的数据：")
print(X_reduced)
```

这些示例代码演示了如何使用不同的降维方法对数据进行降维，并打印降维后的数据。在实际应用中，你可以根据数据集的特点和任务需求选择合适的降维方法，并根据降维结果进行进一步的数据分析、可视化或建模。

在降维过程中，可以使用降维方法提供的可解释性分析降维结果，了解每个特征的重要性，选择适当的降维维度，并根据需要进行可视化或后续的数据分析任务。
