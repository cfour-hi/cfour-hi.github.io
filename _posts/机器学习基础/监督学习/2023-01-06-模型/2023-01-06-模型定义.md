---
title: 机器学习基础-监督学习-线性回归之模型定义
categories: [机器学习]
tags: [人工智能, 机器学习, 监督学习]
math: true
---

在监督学习中，模型定义是指如何建立输入特征和输出标签之间的关系。不同的算法有不同的模型定义方法。以下是几种常见的模型定义以及对应的公式或代码示例：

1. 线性回归模型定义：

线性回归模型假设输入特征和输出标签之间存在线性关系。其模型定义可以表示为：

$$
y = w1x1 + w2x2 + ... + wnxn + b
$$

其中，x1, x2, ..., xn 是输入特征，w1, w2, ..., wn 是特征的权重，b 是偏置项，y 是预测的输出标签。

代码示例（使用 Python 和 NumPy 库）：

```python
import numpy as np

# 输入特征
X = np.array([[x1, x2, ...],  # 样本1的特征
              [x1, x2, ...],  # 样本2的特征
              ...])

# 输出标签
y = np.array([y1, y2, ...])

# 添加偏置项
X = np.hstack((X, np.ones((X.shape[0], 1))))

# 计算权重
w = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)
```

2. 逻辑回归模型定义：

逻辑回归模型用于解决二分类问题，模型定义采用逻辑函数（sigmoid 函数）将线性组合的结果映射到[0, 1]的概率范围内。其模型定义可以表示为：

$$
y = sigmoid(w1x1 + w2x2 + ... + wnxn + b)
$$

其中，x1, x2, ..., xn 是输入特征，w1, w2, ..., wn 是特征的权重，b 是偏置项，sigmoid 函数将线性组合的结果映射到[0, 1]之间的概率值。

代码示例（使用 Python 和 NumPy 库）：

```python
import numpy as np

# 输入特征
X = np.array([[x1, x2, ...],  # 样本1的特征
              [x1, x2, ...],  # 样本2的特征
              ...])

# 输出标签
y = np.array([y1, y2, ...])

# 添加偏置项
X = np.hstack((X, np.ones((X.shape[0], 1))))

# 定义sigmoid函数
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

# 计算权重
w = np.random.randn(X.shape[1])  # 随机初始化权重

# 定义模型输出
y_pred = sigmoid(X.dot(w))
```

3. 支持向量机模型定义：

支持向量机（Support Vector Machines，SVM）是一种常用的分类算法。其模型定义基于将输入特征映射到高维空间中，通过寻找一个最优的超平面来实现分类。模型定义可以表示为：

$$
y = sign(w1x1 + w2x2 + ... + wnxn + b)
$$

其中，x1, x2, ..., xn 是输入特征，w1, w2, ..., wn 是特征的权重，b 是偏置项，sign 函数根据线性组合的结果给出分类的预测结果。

代码示例（使用 Python 和 Scikit-learn 库）：

```python
from sklearn.svm import SVC

# 输入特征
X = [[x1, x2, ...],  # 样本1的特征
     [x1, x2, ...],  # 样本2的特征
     ...]

# 输出标签
y = [y1, y2, ...]

# 创建SVM分类器对象
clf = SVC(kernel='linear')

# 训练模型
clf.fit(X, y)

# 预测新样本
y_pred = clf.predict([[new_x1, new_x2, ...]])
```

4. 决策树模型定义：

决策树模型使用树形结构来进行分类或回归任务。在分类任务中，决策树通过一系列的分裂节点来划分样本，每个节点根据特征的取值选择一个分支。模型定义可以表示为一系列的判断条件和结果。

代码示例（使用 Python 和 Scikit-learn 库）：

```python
from sklearn.tree import DecisionTreeClassifier

# 输入特征
X = [[x1, x2, ...],  # 样本1的特征
     [x1, x2, ...],  # 样本2的特征
     ...]

# 输出标签
y = [y1, y2, ...]

# 创建决策树分类器对象
clf = DecisionTreeClassifier()

# 训练模型
clf.fit(X, y)

# 预测新样本
y_pred = clf.predict([[new_x1, new_x2, ...]])
```

以上是几种常见监督学习模型的定义及相应的代码示例。实际应用中，根据具体问题的特点和算法的选择，模型的定义可能会有所调整和扩展。
